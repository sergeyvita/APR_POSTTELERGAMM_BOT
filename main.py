import os
import logging
from telegram import Update, ChatAction
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
import openai
import pytesseract
from PIL import Image
from pydub import AudioSegment
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è :))
load_dotenv()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TESSERACT_CMD = os.getenv("TESSERACT_CMD")
WEBHOOK_URL = os.getenv("WEBHOOK_URL")

pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
openai.api_key = OPENAI_API_KEY

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

PROMPT = (
    "–≠—Ç–æ—Ç GPT –≤—ã—Å—Ç—É–ø–∞–µ—Ç –≤ —Ä–æ–ª–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–∑–¥–∞—Ç–µ–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –¢–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª–∞ –ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤. "
    "–û–Ω —Å–æ–∑–¥–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø—Ä–æ–¥–∞—é—â–∏–µ –ø–æ—Å—Ç—ã –Ω–∞ —Ç–µ–º—ã –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏, —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤–∞, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π, "
    "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Ä–∞—Å—á–µ—Ç—ã –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∫–≤–∞—Ä—Ç–∏—Ä. –ï—Å–ª–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è —Ä–∞—Å—á–µ—Ç —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –∫–≤–∞—Ä—Ç–∏—Ä, –∫–∞–∂–¥–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –ø–æ —Å—Ç–æ–∏–º–æ—Å—Ç–∏, "
    "–ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–º—É –≤–∑–Ω–æ—Å—É, –ø—Ä–æ—Ü–µ–Ω—Ç–Ω–æ–π —Å—Ç–∞–≤–∫–µ, –µ–∂–µ–º–µ—Å—è—á–Ω–æ–º—É –ø–ª–∞—Ç–µ–∂—É –ø—Ä–æ–ø–∏—Å—ã–≤–∞—é—Ç—Å—è –∫–∞–∂–¥–∞—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ—á–∫–µ –∂–∏—Ä–Ω—ã–º —à—Ä–∏—Ñ—Ç–æ–º. "
    "–ö–æ–Ω—Ç–µ–Ω—Ç –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ –≤–Ω–∏–º–∞–Ω–∏—è, —É–¥–µ—Ä–∂–∞–Ω–∏–µ –∞—É–¥–∏—Ç–æ—Ä–∏–∏ –∏ —Å—Ç–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏–π (–Ω–∞–ø—Ä–∏–º–µ—Ä, –æ–±—Ä–∞—â–µ–Ω–∏—è –∑–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–µ–π –∏–ª–∏ –ø–æ–∫—É–ø–∫–∏). "
    "GPT —É—á–∏—Ç—ã–≤–∞–µ—Ç –¥–µ–ª–æ–≤–æ–π, –Ω–æ –Ω–µ —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–æ–Ω –∏ —Å—Ç—Ä–µ–º–∏—Ç—Å—è –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–º, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º –∏ –≤–æ–≤–ª–µ–∫–∞—é—â–∏–º. –ü–æ—Å—Ç—ã –∫—Ä–∞—Å–∏–≤–æ –æ—Ñ–æ—Ä–º–ª—è—é—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —ç–º–æ–¥–∑–∏ "
    "–≤ —Å—Ç–∏–ª–µ '—ç–Ω–µ—Ä–≥–∏—á–Ω—ã–π –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π', –¥–æ–±–∞–≤–ª—è—è –¥–∏–Ω–∞–º–∏—á–Ω–æ—Å—Ç–∏ –∏ –≤–æ–≤–ª–µ—á–µ–Ω–Ω–æ—Å—Ç–∏. –ù–∞–ø—Ä–∏–º–µ—Ä: üåá –¥–ª—è —Ç–µ–º—ã —Å—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–∞, ‚ú® –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤, "
    "üì≤ –¥–ª—è –ø—Ä–∏–∑—ã–≤–æ–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é. –í—Å–µ –ø–æ—Å—Ç—ã —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç —á–µ—Ç–∫–∏–µ –ø—Ä–∏–∑—ã–≤—ã –∫ –¥–µ–π—Å—Ç–≤–∏—é, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω—Ç–∞–∫—Ç–∞—Ö –∏ –≥–∏–ø–µ—Ä—Å—Å—ã–ª–∫–∏. "
    "–ï—Å–ª–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–æ–∫–∞–∑–∞—Ç—å —Ä–∞—Å—á–µ—Ç—ã –ø–æ –∫–≤–∞—Ä—Ç–∏—Ä–∞–º, —Ç–æ –∂–∏—Ä–Ω—ã–º –≤—ã–¥–µ–ª—è—é—Ç—Å—è –∫–æ–º–Ω–∞—Ç–Ω–æ—Å—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—ã, –ø–ª–æ—â–∞–¥—å –∏ –µ–∂–µ–º–µ—Å—è—á–Ω—ã–π –ø–ª–∞—Ç–µ–∂ –ø–æ –∏–ø–æ—Ç–µ—á–Ω–æ–º—É –∫—Ä–µ–¥–∏—Ç—É. "
    "–í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞ –ø–µ—Ä–µ–¥ —Ö—ç—à—Ç–µ–≥–∞–º–∏ —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ '–ê—Å—Å–æ—Ü–∏–∞—Ü–∏—è –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤', –Ω–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞ 8-800-550-23-93."
)

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –ê—Å—Å–æ—Ü–∏–∞—Ü–∏–∏ –∑–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤. –ó–∞–¥–∞–≤–∞–π—Ç–µ —Å–≤–æ–∏ –≤–æ–ø—Ä–æ—Å—ã, –æ—Ç–ø—Ä–∞–≤–ª—è–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–ª–∏ —Ñ–æ—Ç–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    chat_id = update.message.chat.id

    # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç"
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": PROMPT},
                {"role": "user", "content": user_message}
            ],
            max_tokens=500,
            temperature=0.7
        )
        reply = response['choices'][0]['message']['content'].strip()
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    photo_file = await update.message.photo[-1].get_file()
    image_path = "image.jpg"
    await photo_file.download_to_drive(image_path)

    logging.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {image_path}")

    try:
        extracted_text = pytesseract.image_to_string(Image.open(image_path), lang='rus+eng')
        if extracted_text.strip():
            logging.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {extracted_text}")

            # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç"
            await context.bot.send_chat_action(chat_id=update.message.chat.id, action=ChatAction.TYPING)

            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": PROMPT},
                    {"role": "user", "content": f"–¢–µ–∫—Å—Ç —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {extracted_text}"}
                ],
                max_tokens=1500,
                temperature=1
            )
            reply = response['choices'][0]['message']['content'].strip()
            await update.message.reply_text(reply)
        else:
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω.")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    voice_file = await update.message.voice.get_file()
    audio_path = "audio.ogg"
    wav_path = "audio.wav"
    await voice_file.download_to_drive(audio_path)

    logging.info(f"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –ø–æ –ø—É—Ç–∏: {audio_path}")

    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ WAV
        audio = AudioSegment.from_ogg(audio_path)
        audio.export(wav_path, format="wav")

        # –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å Google Speech API –∏–ª–∏ –¥—Ä—É–≥—É—é —Å–∏—Å—Ç–µ–º—É)
        transcript_response = openai.Audio.transcribe(
            model="whisper-1",
            file=open(wav_path, "rb")
        )

        transcript = transcript_response['text']
        logging.info(f"–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {transcript}")

        # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Å—Ç–∞—Ç—É—Å "–ø–µ—á–∞—Ç–∞–µ—Ç"
        await context.bot.send_chat_action(chat_id=update.message.chat.id, action=ChatAction.TYPING)

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": PROMPT},
                {"role": "user", "content": transcript}
            ],
            max_tokens=500,
            temperature=0.7
        )
        reply = response['choices'][0]['message']['content'].strip()
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

if __name__ == '__main__':
    application = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(MessageHandler(filters.VOICE, handle_voice))

    # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ–±—Ö—É–∫–∞
    logging.info("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤–µ–±—Ö—É–∫–∞")
    application.run_webhook(
        listen="0.0.0.0",
        port=int(os.getenv("PORT", "8080")),
        webhook_url=WEBHOOK_URL
    )